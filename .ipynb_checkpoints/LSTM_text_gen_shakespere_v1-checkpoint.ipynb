{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demonstrated-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model trained to generate sonnets in the style of Shakespere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sticky-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-underwear",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Loading precleaned sonnet data from Gutenberg.org https://www.gutenberg.org/cache/epub/1041/pg1041.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "occupational-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=(open(\"sonnets.txt\").read())\n",
    "text=text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-screw",
   "metadata": {},
   "source": [
    "# Create character/word maps \n",
    "This assings each unique char/word a numeric value from the following dict. NOTE THE FOLLOWING IS CHAR MAPPING, ALTHOUGH WORD MAPPING SUPPOSADLY GIVES HIGHER ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spiritual-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-definition",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unexpected-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "romantic-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-dealer",
   "metadata": {},
   "source": [
    "x = train array, y = target array \n",
    "seq_length = required seq of chars before predicitng the following chars i.e initial seed string \n",
    "the for loop iterates through the full text imput file -> creating seqs stored in x against true values stored in y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lined-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-peripheral",
   "metadata": {},
   "source": [
    "# Model training \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-program",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "Baseline model with small number of layers and training epochs p.s even the simple models take agggggggeeeeessssss to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "romantic-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foreign-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 2405s 2s/step - loss: 2.9541\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_modified, Y_modified, epochs=1, batch_size=100)\n",
    "\n",
    "model.save_weights('text_generator_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "laughing-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('text_generator_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-raising",
   "metadata": {},
   "source": [
    "## Generating text - baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stock-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_mapped = X[99]\n",
    "full_string = [n_to_char[value] for value in string_mapped]\n",
    "# generating characters\n",
    "for i in range(400):\n",
    "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "    x = x / float(len(characters))\n",
    "\n",
    "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "    seq = [n_to_char[value] for value in string_mapped]\n",
    "    full_string.append(n_to_char[pred_index])\n",
    "\n",
    "    string_mapped.append(pred_index)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "boxed-primary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but as the riper should by time decease,\\n  his tender heir might bear his memory:\\n  but thou, contra              thi th the the the the the the the the the she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining text\n",
    "txt=\"\"\n",
    "for char in full_string:\n",
    "    txt = txt+char\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-consideration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
